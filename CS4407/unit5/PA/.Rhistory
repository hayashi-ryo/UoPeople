install.packages("shiny")
install.packages("learnr")
install.packages("ISLR")
D <- data.frame(
x1=c(0.58, 0.86, 0.29, 0.20, 0.56, 0.28, 0.08, 0.41, 0.22, 0.35,
0.59, 0.22, 0.26, 0.12, 0.65, 0.70, 0.30, 0.70, 0.39, 0.72,
0.45, 0.81, 0.04, 0.20, 0.95),
x2=c(0.71, 0.13, 0.79, 0.20, 0.56, 0.92, 0.01, 0.60, 0.70, 0.73,
0.13, 0.96, 0.27, 0.21, 0.88, 0.30, 0.15, 0.09, 0.17, 0.25,
0.30, 0.32, 0.82, 0.98, 0.00),
y=c(1.45, 1.93, 0.81, 0.61, 1.55, 0.95, 0.45, 1.14, 0.74, 0.98,
1.41, 0.81, 0.89, 0.68, 1.39, 1.53, 0.91, 1.49, 1.38, 1.73,
1.11, 1.68, 0.66, 0.69, 1.98)
)
head(D)
summary(D)
# 散布図を作成
plot(D$x1, D$y, main="x1とyの関係", xlab="x1", ylab="y")
plot(D$x2, D$y, main="x2とyの関係", xlab="x2", ylab="y")
# 散布図を作成
plot(D$x1, D$y, main="x1-y", xlab="x1", ylab="y")
plot(D$x2, D$y, main="x2-y", xlab="x2", ylab="y")
plot(D$x1, D$y, main="x1-y", xlab="x1", ylab="y")
plot(D$x2, D$y, main="x2-y", xlab="x2", ylab="y")
model <- lm(y ~ x1 + x2, data=D)
summary(model)
summary(model)
confint(model, level=0.95)
rss <- sum(residuals(model)^2)
sigma_squared <- rss / (nrow(D) - length(coef(model)))
sigma_squared
summary(model)\
summary(model)
sigma_squared
confint(model, level=0.95)
rss <- sum(residuals(model)^2)
sigma_squared <- rss / (nrow(D) - length(coef(model)))
sigma_squared
clear
model <- lm(y ~ x1 + x2, data=D)
summary(model)
# 信頼区間の計算
confint(model, level=0.95)
confint(model, level=0.95)
rss <- sum(residuals(model)^2)
sigma_squared <- rss / (nrow(D) - length(coef(model)))
sigma_squared
reduced_model <- lm(y ~ x1, data=D)
summary(reduced_model)
# 残差プロット
plot(reduced_model$fitted.values, residuals(reduced_model),
main="残差プロット", xlab="予測値", ylab="残差")
abline(h=0, col="red")
# Residual plot
plot(reduced_model$fitted.values, residuals(reduced_model),
main="Residual Plot", xlab="Fitted Values", ylab="Residuals")
abline(h=0, col="red")
# Residual plot
plot(reduced_model$fitted.values, residuals(reduced_model),
main="Residual Plot", xlab="Fitted Values", ylab="Residuals")
abline(h=0, col="red")
qqnorm(residuals(reduced_model))
qqline(residuals(reduced_model), col="red")
shapiro.test(residuals(reduced_model))
hist(residuals(reduced_model), main="Histogram of Residuals", xlab="Residuals", breaks=10, col="gray")
# Create a sequence of x values for plotting
x_seq <- seq(0, 1, length.out = 100)
# Predict fitted values and intervals
predictions <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "confidence")
predictions_pred <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "prediction")
# Plot the data and fitted line
plot(D$x1, D$y, main="Fitted Line with Confidence and Prediction Intervals",
xlab="x1", ylab="y", pch=16, col="blue")
lines(x_seq, predictions[, "fit"], col="red", lwd=2)  # Fitted line
lines(x_seq, predictions[, "lwr"], col="green", lty=2)  # Confidence lower
lines(x_seq, predictions[, "upr"], col="green", lty=2)  # Confidence upper
lines(x_seq, predictions_pred[, "lwr"], col="orange", lty=3)  # Prediction lower
lines(x_seq, predictions_pred[, "upr"], col="orange", lty=3)  # Prediction upper
legend("topleft", legend=c("Fitted Line", "Confidence Interval", "Prediction Interval"),
col=c("red", "green", "orange"), lty=c(1, 2, 3), lwd=2)
# Create a sequence of x values for plotting
x_seq <- seq(0, 1, length.out = 100)
# Predict fitted values and intervals
predictions <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "confidence")
predictions_pred <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "prediction")
# Plot the data and fitted line
plot(D$x1, D$y, main="Fitted Line with Confidence and Prediction Intervals",
xlab="x1", ylab="y", pch=16, col="blue")
lines(x_seq, predictions[, "fit"], col="red", lwd=2)  # Fitted line
lines(x_seq, predictions[, "lwr"], col="green", lty=2)  # Confidence lower
lines(x_seq, predictions[, "upr"], col="green", lty=2)  # Confidence upper
lines(x_seq, predictions_pred[, "lwr"], col="orange", lty=3)  # Prediction lower
lines(x_seq, predictions_pred[, "upr"], col="orange", lty=3)  # Prediction upper
legend("topleft", legend=c("Fitted Line", "Confidence Interval", "Prediction Interval"),
col=c("red", "green", "orange"), lty=c(1, 2, 3), lwd=2)
# Create a sequence of x values for plotting
x_seq <- seq(0, 1, length.out = 100)
# Predict fitted values and intervals
predictions <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "confidence")
predictions_pred <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "prediction")
# Plot the data and fitted line
plot(D$x1, D$y, main="Fitted Line with Confidence and Prediction Intervals",
xlab="x1", ylab="y", pch=16, col="blue")
lines(x_seq, predictions[, "fit"], col="red", lwd=2)  # Fitted line
lines(x_seq, predictions[, "lwr"], col="green", lty=2)  # Confidence lower
lines(x_seq, predictions[, "upr"], col="green", lty=2)  # Confidence upper
lines(x_seq, predictions_pred[, "lwr"], col="orange", lty=3)  # Prediction lower
lines(x_seq, predictions_pred[, "upr"], col="orange", lty=3)  # Prediction upper
legend("topleft", legend=c("Fitted Line", "Confidence Interval", "Prediction Interval"),
col=c("red", "green", "orange"), lty=c(1, 2, 3), lwd=2)
# Create a sequence of x values for plotting
x_seq <- seq(0, 1, length.out = 100)
# Predict fitted values and intervals
predictions <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "confidence")
predictions_pred <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "prediction")
# Plot the data and fitted line
plot(D$x1, D$y, main="Fitted Line with Confidence and Prediction Intervals",
xlab="x1", ylab="y", pch=16, col="blue")
lines(x_seq, predictions[, "fit"], col="red", lwd=2)  # Fitted line
lines(x_seq, predictions[, "lwr"], col="green", lty=2)  # Confidence lower
lines(x_seq, predictions[, "upr"], col="green", lty=2)  # Confidence upper
lines(x_seq, predictions_pred[, "lwr"], col="orange", lty=3)  # Prediction lower
lines(x_seq, predictions_pred[, "upr"], col="orange", lty=3)  # Prediction upper
legend("topleft", legend=c("Fitted Line", "Confidence Interval", "Prediction Interval"),
col=c("red", "green", "orange"), lty=c(1, 2, 3), lwd=2)
# Create a sequence of x values for plotting
x_seq <- seq(0, 1, length.out = 100)
# Predict fitted values and intervals
predictions <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "confidence")
predictions_pred <- predict(reduced_model, newdata = data.frame(x1 = x_seq),
interval = "prediction")
# Plot the data and fitted line
plot(D$x1, D$y, main="Fitted Line with Confidence and Prediction Intervals",
xlab="x1", ylab="y", pch=16, col="blue")
lines(x_seq, predictions[, "fit"], col="red", lwd=2)  # Fitted line
lines(x_seq, predictions[, "lwr"], col="green", lty=2)  # Confidence lower
lines(x_seq, predictions[, "upr"], col="green", lty=2)  # Confidence upper
lines(x_seq, predictions_pred[, "lwr"], col="orange", lty=3)  # Prediction lower
lines(x_seq, predictions_pred[, "upr"], col="orange", lty=3)  # Prediction upper
legend("topleft", legend=c("Fitted Line", "Confidence Interval", "Prediction Interval"),
col=c("red", "green", "orange"), lty=c(1, 2, 3), lwd=2)
D <- data.frame(
y=c(9.29, 12.67, 12.42, 0.38, 20.77, 9.52, 2.38, 7.46),
x1=c(1.00, 2.00, 3.00, 4.00, 5.00, 6.00, 7.00, 8.00),
x2=c(4.00, 12.00, 16.00, 8.00, 32.00, 24.00, 20.00, 28.00)
)
model1 <- lm(y ~ x1, data=D)
summary(model1)
model2 <- lm(y ~ x2, data=D)
summary(model2)
plot(D$x1, D$y, main="Observed vs Fitted (Model 1)", xlab="x1", ylab="y", pch=16, col="blue")
abline(model1, col="red", lwd=2)
plot(D$x2, D$y, main="Observed vs Fitted (Model 2)", xlab="x2", ylab="y", pch=16, col="blue")
abline(model2, col="red", lwd=2)
summary(model)
summary(mode1),summary(model2)
summary(mode1)
summary(model1)
summary(model2)
par(mfrow=c(1, 2))
plot(D$x1, D$y, main="Observed vs Fitted (Model 1)", xlab="x1", ylab="y", pch=16, col="blue")
abline(model1, col="red", lwd=2)
# Plot for Model 2
plot(D$x2, D$y, main="Observed vs Fitted (Model 2)", xlab="x2", ylab="y", pch=16, col="blue")
abline(model2, col="red", lwd=2)
# Reset the layout to default
par(mfrow=c(1, 1))
summary(model1)
summary(model2)
# Model 1
model1 <- lm(y ~ x1, data=D)
summary(model1)
confint(model1, level=0.95)
# Model 2
model2 <- lm(y ~ x2, data=D)
summary(model2)
confint(model2, level=0.95)
model1 <- lm(y ~ x1, data=D)
summary(model1)
confint(model1, level=0.95)
summary(model2)
confint(model2, level=0.95)
A1 <- c(0, 0)
A2 <- c(1, 1)
A3 <- c(2, 2)
B1 <- c(6, 6)
B2 <- c(5.5, 7)
B3 <- c(6.5, 5)
train <- matrix(c(0, 0, 1, 1, 2, 2, 6, 6, 5.5, 7, 6.5, 5), ncol = 2, byrow = TRUE)
colnames(train) <- c("X", "Y")
cl <- factor(c("A", "A", "A", "B", "B", "B"))
test1 <- c(4, 4)
test2 <- c(3.5, 3.5)
str(train)
print(cl)
table(cl)
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "トレーニングデータの可視化")
legend("topright", legend = levels(cl), col = 1:2, pch = 16)
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "visual")
print(test1)
library(class)
result <- knn(train, test = matrix(test1, ncol = 2), cl, k = 1)
print(result)
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "Plot the Chart")
legend("topright", legend = levels(cl), col = 1:2, pch = 16)
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "Plot the Chart")
legend("topright", legend = levels(cl), col = 1:2, pch = 16)
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "Plot the Chart")
legend("topleft", legend = levels(cl), col = 1:2, pch = 16)
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "Plot the Chart")
legend("topright", legend = levels(cl), col = 1:2, pch = 16)
library(class)
test1 <- matrix(c(4, 4), ncol = 2)
result_k1 <- knn(train, test1, cl, k = 1)
print(result_k1)
summary(result_k1)
A1 <- c(0, 0)
A2 <- c(1, 1)
A3 <- c(2, 2)
B1 <- c(6, 6)
B2 <- c(5.5, 7)
B3 <- c(6.5, 5)
test1 <- c(4, 4)
test2 <- c(3.5, 3.5)
train <- matrix(c(0, 0, 1, 1, 2, 2, 6, 6, 5.5, 7, 6.5, 5), ncol = 2, byrow = TRUE)
colnames(train) <- c("X", "Y")
cl <- factor(c("A", "A", "A", "B", "B", "B"))
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "Plot the Chart")
legend("topright", legend = levels(cl), col = 1:2, pch = 16)
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "Plot the Chart")
legend("topleft", legend = levels(cl), col = 1:2, pch = 16)
```
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "Plot the Chart")
legend("topleft", legend = levels(cl), col = 1:2, pch = 16)
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "Plot the Chart")
legend("topleft", legend = levels(cl), col = 1:2, pch = 16)
```
plot(train, col = cl, pch = 16, xlab = "X", ylab = "Y", main = "Plot the Chart")
legend("topleft", legend = levels(cl), col = 1:2, pch = 16)
library(class)
test1 <- matrix(c(4, 4), ncol = 2)
result_k1 <- knn(train, test1, cl, k = 1)
print(result_k1)
summary(result_k1)
library(class)
test1 <- matrix(c(4, 4), ncol = 2)
result_k1 <- knn(train, test1, cl, k = 1)
print(result_k1)
summary(result_k1)
# 新しいテストケースの定義
test2 <- matrix(c(3.5, 3.5), ncol = 2)
# kNNアルゴリズムの実行 (k = 1)
result_k1_test2 <- knn(train, test2, cl, k = 1)
# 結果の出力
print(result_k1_test2)
# 結果の詳細確認
summary(result_k1_test2)
test2 <- matrix(c(3.5, 3.5), ncol = 2)
result_k1_test2 <- knn(train, test2, cl, k = 1)
print(result_k1_test2)
summary(result_k1_test2)
test2 <- matrix(c(3.5, 3.5), ncol = 2)
result_k1_test2 <- knn(train, test2, cl, k = 1)
print(result_k1_test2)
summary(result_k1_test2)
test_batch <- matrix(c(4, 4, 3, 3, 5, 6, 7, 7), ncol = 2, byrow = TRUE)
result_batch <- knn(train, test_batch, cl, k = 3)
print(result_batch)
summary(result_batch)
setwd("/Users/hayashir/work/Github/UoPeople/CS4407-branch/CS4407/unit5/PA")
library(rpart)
library(mlbench)
ionosphere_data <- read.table("Ionosphere.txt",
header = FALSE,
sep = ",",
stringsAsFactors = TRUE)
colnames(ionosphere_data) <- c(paste0("V", 1:34), "Class")
head(ionosphere_data)
summary(ionosphere_data)
ionosphere_tree <- rpart(Class ~ ., data = ionosphere_data)
print(summary(ionosphere_tree))
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
text(ionosphere_tree, use.n = TRUE, all = TRUE, cex = 0.8)
text(ionosphere_tree, use.n = TRUE, all = TRUE, cex = 0.8)
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
# ノードにラベルを追加
text(ionosphere_tree, use.n = TRUE, all = TRUE, cex = 0.8)
# ノードにラベルを追加
text(ionosphere_tree, use.n = TRUE, all = TRUE, cex = 1)
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
# ノードにラベルを追加
text(ionosphere_tree, use.n = TRUE, all = TRUE, cex = 2)
# ノードにラベルを追加
text(ionosphere_tree, use.n = FALSE, all = TRUE, cex = 2)
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
# ノードにラベルを追加
text(ionosphere_tree, use.n = FALSE, all = TRUE, cex = 2)
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
text(ionosphere_tree, use.n = TRUE, all = False, cex = 0.8)
text(ionosphere_tree, use.n = TRUE, all = FALSE, cex = 0.8)
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
text(ionosphere_tree, use.n = TRUE, all = FALSE, cex = 1.)
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
text(ionosphere_tree, use.n = TRUE, all = TRUE, cex = 1.2)
par(mar = c(4, 4, 4, 4))  # 下, 左, 上, 右 の順で余白を指定
# 決定木の描画
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
text(ionosphere_tree, use.n = TRUE, all = TRUE, cex = 0.8)
par(mar = c(4, 4, 4, 4))  # 下, 左, 上, 右 の順で余白を指定
# 決定木の描画
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
text(ionosphere_tree, use.n = TRUE, all = TRUE, cex = 1)
par(mar = c(4, 4, 4, 4))
# 決定木の描画
plot(ionosphere_tree, uniform = TRUE, main = "Ionosphere Decision Tree")
# ノードにラベルを追加
text(ionosphere_tree, use.n = TRUE, all = TRUE, cex = 0.8)
set.seed(123)
train_indices <- sample(1:nrow(ionosphere_data), 0.7 * nrow(ionosphere_data))
train_data <- ionosphere_data[train_indices, ]
test_data <- ionosphere_data[-train_indices, ]
ionosphere_tree_train <- rpart(Class ~ ., data = train_data)
print(summary(ionosphere_tree_train))
test_predictions <- predict(ionosphere_tree_train, newdata = test_data, type = "class")
confusion_matrix <- table(test_predictions, test_data$Class)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(confusion_matrix)
print(paste("Accuracy: ", round(accuracy * 100, 2), "%"))
